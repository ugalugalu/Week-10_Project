{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/ubogalugalu/opt/anaconda3/lib/python3.9/site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/ubogalugalu/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: for Random Forests 0.8666666666666667\n",
      "Best Max Depth: 3\n",
      "Best Num Trees: 9\n",
      "Accuracy for Gradient Boosting:  0.8\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, round\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier,GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# Filter out warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ubo\") \\\n",
    "    .config(\"spark.logConf\", \"false\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set the log level to ERROR or FATAL. This is to suppress the warnings.\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Load the dataset\n",
    "data = spark.read.csv(\"telecom_dataset.csv\", header= True, inferSchema=True)\n",
    "\n",
    "#Take care of the duplicates in case they are there\n",
    "data.drop_duplicates()\n",
    "\n",
    "# Select relevant columns for churn prediction\n",
    "selected_columns = [\"Gender\", \"Age\", \"Contract\", \"MonthlyCharges\", \"TotalCharges\",\"Churn\"]\n",
    "data = data.select(selected_columns)\n",
    "\n",
    "# Convert categorical columns to numeric using StringIndexer\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
    "    for column in [\"Gender\", \"Contract\",\"Churn\"]\n",
    "]\n",
    "indexers.append(StringIndexer(inputCol=\"Churn\", outputCol=\"label\"))  # Convert churn to label column\n",
    "indexer_pipeline = Pipeline(stages=indexers)\n",
    "data = indexer_pipeline.fit(data).transform(data)\n",
    "\n",
    "#Feature Engineering\n",
    "# Feature Engineering.Add a new column which calculates average charges by dividing total charges by 12\n",
    "data = data.withColumn(\"AverageCharges\", col(\"TotalCharges\")/12)\n",
    "data = data.withColumn(\"AverageCharges\", round(col(\"AverageCharges\"), 2))\n",
    "\n",
    "# Select the feature and label columns\n",
    "feature_columns = [\"Age\", \"Gender_index\", \"Age\", \"Contract_index\",\"AverageCharges\"]\n",
    "label_column = \"label\"\n",
    "\n",
    "# Convert the features columns to a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf = RandomForestClassifier(labelCol=label_column, featuresCol=\"features\")\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [3,4,5]) \\\n",
    "    .addGrid(rf.numTrees, [i for i in range(8,11)]) \\\n",
    "    .build()\n",
    "\n",
    "# Create the evaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=label_column, rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# Create the cross-validator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Run cross-validation to find the best model\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# Get the best model\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "predictions = best_model.transform(test_data)\n",
    "\n",
    "#Create Gradient Boost Model\n",
    "gbt = GBTClassifier(labelCol=label_column, featuresCol=\"features\")\n",
    "\n",
    "#Train the gradient boost model\n",
    "gbt_model = gbt.fit(train_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Evaluate the models\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions) \n",
    "print(\"Accuracy: for Random Forests\", accuracy)\n",
    "\n",
    "print(\"Best Max Depth:\", best_model.getMaxDepth())\n",
    "print(\"Best Num Trees:\", best_model.getNumTrees)\n",
    "\n",
    "area_under_curve = evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "accuracy = evaluator.evaluate(gbt_predictions) \n",
    "print(\"Accuracy for Gradient Boosting: \", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: Two models were trained and evaluated i.e Random Forests and Gradient Boosting. The best model was Random forests and after Hyper parameter tuning, the best hyper parameters were 3 for maximum depth and 9 for number of trees. Random forest achieved Accuracy of 0.86 while the Gradient Boosting model achieved an accuracy of 0.8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c606041d7f3945e33ec85d94395ab6e1caa578dd418ab71041339227480199b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
